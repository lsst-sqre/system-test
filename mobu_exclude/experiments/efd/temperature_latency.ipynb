{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature latency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we demonstrate how to extract data from the DM-EFD using [aioinflux](https://aioinflux.readthedocs.io/en/stable/index.html), a Python client for InfluxDB, and proceed with data analysis using Pandas dataframes. \n",
    "\n",
    "This is complementaty to the [Chronograf](https://test-chronograf-efd.lsst.codes) interface which we use for time-series visualization.\n",
    "\n",
    "In addition to `aioinflux`, you'll need to install `pandas`, `numpy` and `matplotlib` to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt\n",
    "from astropy.time import Time, TimeDelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import LinearAxis, Range1d, Span, Label\n",
    "output_notebook()\n",
    "\n",
    "from lsst_efd_client import EfdClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll access the DM-EFD instance deployed at the AuxTel lab in Tucson. You need to be on site or connected to the NOAO VPN. \n",
    "\n",
    "To access the EFD, you will need to put a file called `.lsst/notebook_auth.yaml` in your home directory.  It should be formatted in the following way (substituting the appropriate values, of course).  Ping Anglo or Simon on Slack (`@afausti`, `@ksk`) if you have any problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "test:\n",
    "  username: \"user\"\n",
    "  host: \"endpoint.edu\"\n",
    "  password: \"passwd\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = EfdClient('int_efd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a time range. These must be `astropy.time` objects. We'll specify the end time and use an offset for the start time. This notebook looks at data for the 30 days before 20 March 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = Time('2020-03-20T00:00:00', scale='tai')\n",
    "window = TimeDelta(30*24*3600, format='sec', scale='tai')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the relevant timestamp.  I believe the `sndStamp` is when the message is sent to DDS, so is the earliest timestamp we have for weather data.  The timestamp for when the measurement was recorded in influxDB is in the index of the returned data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamps = await client.select_time_series(\"lsst.sal.Environment.weather\", [\"private_sndStamp\", ], t1-window, t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most operations work on `Timedelta` types, but not the `histogram` function, so we record the difference in seconds here.  Also note that timestamps are actually in TAI, but pandas doesn't know about TAI.  Since we are only looking at time difference, it doesn't matter which system we choose (unless a leap second happens between two of our samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = []\n",
    "for influx_stamp, snd_stamp in zip(tstamps.index.values, tstamps['private_sndStamp']):\n",
    "    deltas.append((pd.Timestamp(influx_stamp, tz=\"GMT\") - pd.Timestamp(snd_stamp - 37, unit='s', tz=\"GMT\")).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = np.array(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = np.median(deltas)\n",
    "mean = deltas.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, edges = np.histogram(deltas, density=True, bins=np.linspace(0, 5, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(title='Latency between influx and snd for the Environment_weather subsystem', background_fill_color=\"#fafafa\")\n",
    "p.yaxis.axis_label = \"Number\"\n",
    "p.xaxis.axis_label = \"Latency (s)\"\n",
    "p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:],\n",
    "       fill_color='navy', line_color='white', alpha=0.5)\n",
    "annotation = Label(x=250, y=250, x_units='screen', y_units='screen',\n",
    "                 text='mean=%.4fs median=%.4fs'%(mean, median),\n",
    "                 border_line_color='black', border_line_alpha=1.0,\n",
    "                 background_fill_color='white', background_fill_alpha=1.0)\n",
    "p.add_layout(annotation)\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
