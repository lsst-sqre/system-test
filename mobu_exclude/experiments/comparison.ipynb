{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of the HSC deblender and scarlet\n",
    "\n",
    "In this demo we look at three different blends using both the HSC deblender and scarlet to deblend them:\n",
    "\n",
    "1. A blend that both the HSC deblender and scarlet deblend well\n",
    "2. A blend that the HSC deblender struggles with but scarlet is successful\n",
    "3. A blend that scarlet shows improved performance over the HSC deblender but still struggles with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping\n",
    "from astropy.visualization import ZScaleInterval\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "\n",
    "from lsst.daf.persistence import Butler\n",
    "from lsst.afw.table import SourceCatalog\n",
    "from lsst.afw.image import MultibandExposure\n",
    "from lsst.meas.algorithms import SourceDetectionTask\n",
    "from lsst.meas.deblender import SourceDeblendConfig, SourceDeblendTask\n",
    "import lsst.meas.extensions.scarlet as mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in each band\n",
    "butler = Butler(\"/datasets/hsc/repo/rerun/RC/w_2019_26/DM-19560/\")\n",
    "dataId = {\"tract\": 9813, \"patch\": \"4,4\"}\n",
    "filters = \"grizy\"\n",
    "coadds = []\n",
    "for f in filters:\n",
    "    coadds.append(butler.get(\"deepCoadd_calexp\", dataId, filter=\"HSC-{}\".format(f.upper())))\n",
    "coadds = MultibandExposure.fromExposures(filters, coadds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detection on the \"r\" band image\n",
    "# In reality this should be done in all bands and then have the\n",
    "# results merged, but for the sake of this tutorial it is faster/easier\n",
    "# to just run detection on a single image.\n",
    "\n",
    "schema = SourceCatalog.Table.makeMinimalSchema()\n",
    "detectionTask = SourceDetectionTask(schema=schema)\n",
    "deblendTask = SourceDeblendTask(schema=schema)\n",
    "table = SourceCatalog.Table.make(schema)\n",
    "detectionResult = detectionTask.run(table, coadds[\"r\"])\n",
    "catalog = detectionResult.sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the subset of the catalog that contains the three blends of interest\n",
    "\n",
    "#parents = [9810, 5245, 7715, 566, 4432, 5867, 10740, 2911, 5003, 5867, 13051]\n",
    "parents = [2520, 3621, 9810]\n",
    "indices = np.zeros((len(catalog),), dtype=bool)\n",
    "for pidx in parents:\n",
    "    indices = indices | (catalog[\"id\"] == pidx)\n",
    "subset = catalog[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the old deblender on the subset of blends and store each catalog in a dictionary\n",
    "catalogs = {}\n",
    "for f in filters:\n",
    "    _catalog = SourceCatalog(catalog.table.clone())\n",
    "    _catalog.extend(subset, deep=True)\n",
    "    catalogs[f] = _catalog\n",
    "    deblendTask.run(coadds[f], catalogs[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.geom import Box2I, Point2I\n",
    "import lsst.afw.image as afwImage\n",
    "\n",
    "\n",
    "def get_old_heavy_image(catalogs, idx):\n",
    "    \"\"\"Load the multiband image data cube for a given source in a blend\n",
    "    \"\"\"\n",
    "    footprints = [catalogs[f][idx].getFootprint() for f in catalogs]\n",
    "    # Since the HSC deblender works separately on each band, we need to\n",
    "    # make an image that fits all of the footprints inside and properly\n",
    "    # project them into the result\n",
    "    xmin = np.min([fp.getBBox().getMinX() for fp in footprints])\n",
    "    ymin = np.min([fp.getBBox().getMinY() for fp in footprints])\n",
    "    xmax = np.max([fp.getBBox().getMaxX() for fp in footprints])\n",
    "    ymax = np.max([fp.getBBox().getMaxY() for fp in footprints])\n",
    "    bbox = Box2I(Point2I(xmin, ymin), Point2I(xmax, ymax))\n",
    "    result = np.zeros((len(catalogs), bbox.getHeight(), bbox.getWidth()))\n",
    "    for b, fp in enumerate(footprints):\n",
    "        _img = afwImage.Image(bbox, dtype=np.float32)\n",
    "        fp.insert(_img)\n",
    "        result[b] += _img.array\n",
    "    return result, bbox\n",
    "\n",
    "def run_scarlet(coadds, catalog, parentId):\n",
    "    \"\"\"Execute scarlet on a given blend\n",
    "    \"\"\"\n",
    "    parent = catalog[catalog[\"id\"] == parentId][0]\n",
    "    foot = parent.getFootprint()\n",
    "    config = mes.ScarletDeblendConfig()\n",
    "    config.maxIter = 200\n",
    "    config.relativeError = 1e-3\n",
    "    blend = mes.deblend(coadds, foot, None, config)\n",
    "    return blend\n",
    "\n",
    "def display_results(coadds, catalogs, blend, parentId, rescale=True, scale_factor=5):\n",
    "    \"\"\"Display the results using the HSC deblender and scarlet side by side\n",
    "    \"\"\"\n",
    "    # Define the color scaling\n",
    "    asinh = AsinhMapping(minimum=0, stretch=1, Q=10)\n",
    "    \n",
    "    parent = catalogs[\"r\"][catalogs[\"r\"][\"id\"] == parentId][0]\n",
    "    bbox = parent.getFootprint().getBBox()\n",
    "    image = coadds[:, bbox].image.array\n",
    "    img_rgb = scarlet.display.img_to_rgb(image[:3], norm=asinh)\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(\"Blend number {0}\".format(parentId))\n",
    "    for k, peak in enumerate(parent.getFootprint().getPeaks()):\n",
    "        px, py = peak.getIx(), peak.getIy()\n",
    "        px = px - bbox.getMinX()\n",
    "        py = py - bbox.getMinY()\n",
    "        plt.text(px, py, str(k), color=\"cyan\")\n",
    "    plt.show()\n",
    "\n",
    "    childrenIdx = np.where(catalogs[\"r\"][\"parent\"] == parentId)[0]\n",
    "    for k, cidx in enumerate(childrenIdx):\n",
    "        # Extract the source model from the hsc deblender\n",
    "        hsc_model, hsc_bbox = get_old_heavy_image(catalogs, int(cidx))\n",
    "        \n",
    "        if rescale:\n",
    "            asinh = AsinhMapping(minimum=0, stretch=hsc_model.max()/scale_factor, Q=10)\n",
    "        \n",
    "        hsc_rgb = scarlet.display.img_to_rgb(hsc_model[:3], norm=asinh)\n",
    "        # Extract the source model from scarlet, convolved with the observed PSFs\n",
    "        scarlet_model = blend.observations[0].render(blend.sources[k].get_model())\n",
    "        \n",
    "        # Project the original image and scarlet model onto the same bbox as the HSC model\n",
    "        xmin, ymin = hsc_bbox.getMin()\n",
    "        xmin -= bbox.getMinX()\n",
    "        ymin -= bbox.getMinY()\n",
    "        width, height = hsc_bbox.getDimensions()\n",
    "        if xmin < 0:\n",
    "            width += xmin\n",
    "            xmin = 0\n",
    "        if ymin < 0:\n",
    "            height += ymin\n",
    "            ymin = 0\n",
    "        slices = (slice(None, 3), slice(ymin, ymin+height), slice(xmin, xmin+width))\n",
    "        \n",
    "        scarlet_rgb = scarlet.display.img_to_rgb(scarlet_model[slices], norm=asinh)\n",
    "        img_rgb = scarlet.display.img_to_rgb(image[slices], norm=asinh)\n",
    "        \n",
    "        fig = plt.figure(figsize=(15, 8))\n",
    "        ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "        ax[0].imshow(img_rgb)\n",
    "        ax[0].set_title(\"Data\")\n",
    "        peak = parent.getFootprint().getPeaks()[k]\n",
    "        px, py = peak.getIx(), peak.getIy()\n",
    "        px = px - hsc_bbox.getMinX()\n",
    "        py = py - hsc_bbox.getMinY()\n",
    "        ax[0].plot(px, py, \"cx\", mew=2)\n",
    "        ax[1].imshow(hsc_rgb)\n",
    "        ax[1].set_title(\"HSC {0}\".format(k))\n",
    "        ax[2].imshow(scarlet_rgb)\n",
    "        ax[2].set_title(\"scarlet {0}\".format(k))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Well Deblended Scene\n",
    "\n",
    "We first look at a blend that both deblenders are able to deblend. This is a fairly typical blend in that there are a number of sources in the `Footprint`, some of which are more isolated while others are blended more closely. This illustrates the success of using monotonicity and symmetry in order to deblend a scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentId = 2520\n",
    "blend = run_scarlet(coadds, catalog, parentId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(coadds, catalogs, blend, parentId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A More Difficult Blend\n",
    "\n",
    "This is a more challenging blend. What makes this blend difficult for the HSC deblender is that many of the sources have neighbors on opposite sides of the peak, meaning symmetry is no longer strong enough to constraint their flux. By using multiband information and an iterative deblending procedure scarlet is able to successfully deblend scenes like this where the old HSC deblender fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentId = 3621\n",
    "blend2 = run_scarlet(coadds, catalog, parentId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(coadds, catalogs, blend2, parentId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Most Difficult Blend\n",
    "\n",
    "This scene can be thought of as the true test of a deblender. Not only are there 3 bright sources in a row, one of them is a resolved spiral that has asymmetric structures. The HSC deblender struggles due to the three in a row problem that it will always face (see peaks 3, 4, and 5 below).\n",
    "\n",
    "scarlet struggles for now because there is still a bug in determining the center of a source, so the fractional pixel offset from each source poses problems for the symmetry algorithm for the central object. However symmetry is too strict for the spiral (peak 3), which is not symmetric, so scarlet also fails to model that source. But there is still significant improvement for peaks 4 and 5, with a version of scarlet in development that produces a much better model for peak 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentId = 9810\n",
    "blend3 = run_scarlet(coadds, catalog, parentId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(coadds, catalogs, blend3, 9810, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
