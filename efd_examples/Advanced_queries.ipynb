{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced EFD Queries with `aioinflux`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect many user needs to be satisfied by the methods provided by the `EfdClient`, but there are situations when using the instance of the `aioinflux` client made by the `EfdClient` constructor directly is advantageous.\n",
    "There are two specific cases that will be explored in this notebook:\n",
    "\n",
    "1. Use InfluxQL functions and the `GROUP BY time` clause to return aggregated results faster\n",
    "2. Use the chunked requests feature of the `aioinflux` client to speed up long baseline queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct an instance of the `EfdClient` pointing to the \"stable EFD\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from astropy.time import Time, TimeDelta\n",
    "from matplotlib import pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "from lsst_efd_client import EfdClient\n",
    "efd = EfdClient('ldf_stable_efd')\n",
    "cl = efd.influx_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a time window to use in the queries.\n",
    "Timestamps on EFD topics should be in TAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_agg = Time('2021-03-15T12:00:00Z')\n",
    "t1_agg = t2_agg - TimeDelta(5*24*3600, format='sec') # look back over 5 days of data\n",
    "\n",
    "t2_chunk = Time('2021-03-04T12:00:00Z')\n",
    "t1_chunk = Time('2021-02-04T12:00:00Z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is trivial to [resample](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html) `pandas.DataFrame` objects returned by the `EfdClient`.\n",
    "In cases where you know ahead of time that you won't need the full sampling of the data, resampling in the query can provide faster queries as well as making it practical to query on wider time windows.\n",
    "We will be using the [`GROUP BY time`](https://docs.influxdata.com/influxdb/v1.8/query_language/explore-data/#basic-group-by-time-syntax) clause in the influxQL language.\n",
    "\n",
    "In order to resample in this way, a function must be supplied for any field in the topic being returned.\n",
    "Common functions to use will be [aggregations](https://docs.influxdata.com/influxdb/v1.8/query_language/functions/#aggregations) and [selectors](https://docs.influxdata.com/influxdb/v1.8/query_language/functions/#selectors).\n",
    "For the purposes of this demonstration, we will use the `MEAN` function.\n",
    "\n",
    "The time interval in the `GROUP BY time` must be specified as a [duration literal](https://docs.influxdata.com/influxdb/v1.8/query_language/spec/#durations).\n",
    "\n",
    "➔ Note that influxQL is [picky](https://www.influxdata.com/blog/tldr-influxdb-tech-tips-july-21-2016/) about single vs. double quotes, so if you are getting errors, recheck your quoting.\n",
    "\n",
    "➔ Also note that the timestamps in the query indicate the time is in UTC.\n",
    "The timezone is required by influxQL and though we indicate UTC, the time index in influxDB is actually in TAI.\n",
    "Since our times are specified in TAI, this should all work even though we are forced to misstate the timezone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_query_str(beg, end, interval):\n",
    "    return (\"SELECT mean(\\\"ambient_temp\\\") as \\\"temp\\\", mean(\\\"pressure\\\") as \\\"pressure\\\", mean(\\\"humidity\\\") as \\\"humidity\\\" \" +\n",
    "            \"FROM \\\"efd\\\".\\\"autogen\\\".\\\"lsst.sal.WeatherStation.weather\\\" \" +\n",
    "            f\"WHERE time > '{beg.isot}Z' and time <= '{end.isot}Z' \" +\n",
    "            f\"GROUP BY time({interval})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(result):\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, nrows=1)\n",
    "    ax0.plot(result.index, result['temp'])\n",
    "    ax0.set_xlabel('Date')\n",
    "    ax0.set_ylabel('Temperature (ºC)')\n",
    "    ax1.plot(result.index, result['pressure'])\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Pressure (mm Hg)')\n",
    "    ax2.plot(result.index, result['humidity'])\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Relative Humidity (%)')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.subplots_adjust(wspace=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cl.query(make_query_str(t1_agg, t2_agg, '30m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do that query again, but this time use a much wider aggregation window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cl.query(make_query_str(t1_agg, t2_agg, '6h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunked queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At times, the full fidelity data stream is required for processing, but for various reasons fetching all the data at once is impractical.\n",
    "This is where the [chunked query](https://aioinflux.readthedocs.io/en/stable/usage.html#chunked-responses) functionality of `aioinflux` domes in handy.\n",
    "Note that chunked queries can also make large queries more reliable as very long queries sometimes get dropped, resulting in an exception.\n",
    "\n",
    "The simple example here is a demonstration that we have not dropped any weather event for 1 month in early 2021.\n",
    "\n",
    "The default chunk size is 1000.\n",
    "We set it here for demonstration purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = (\"SELECT \\\"private_seqNum\\\" \" +\n",
    "            \"FROM \\\"efd\\\".\\\"autogen\\\".\\\"lsst.sal.WeatherStation.weather\\\" \" +\n",
    "            f\"WHERE time > '{t1_chunk.isot}Z' and time <= '{t2_chunk.isot}Z'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = await cl.query(query_str, chunked=True, chunk_size=500) # The default chunk size is 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_nums = []\n",
    "offset = 0\n",
    "async for c in chunks:\n",
    "    for num in c['private_seqNum']:\n",
    "        if seq_nums and num == 1:\n",
    "            offset = seq_nums[-1] # when the subsystem is rebooted, the sequence starts over\n",
    "        seq_nums.append(num + offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check to make sure the difference between sequence number is always 1 meaning there were no intervening messages that didn't get recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_nums = np.array(seq_nums)\n",
    "diffs = seq_nums[1:] - seq_nums[:-1] - np.ones(len(seq_nums) - 1)\n",
    "print(f'This should be zero: {diffs.sum()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
