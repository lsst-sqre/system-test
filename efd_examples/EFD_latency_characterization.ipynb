{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EFD latency characterization\n",
    "\n",
    "This notebook shows how to get data from the InfluxDB API to characterize the total latency for a message from the time it is sent by SAL to the time it is written to InfluxDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib widget\n",
    "import requests\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.time import Time, TimeDelta\n",
    "\n",
    "from lsst_efd_client import EfdClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = EfdClient('int_efd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving timestamps for a given topic\n",
    "The following timestamps are available (the order reflects the actual message flow through the system) \n",
    "\n",
    "- **private_sndStamp**: TAI timestamp in seconds added by SAL when the message was created\n",
    "- **private_kafkaStamp**: TAI timestamp in seconds added by the SAL Kafka Producer right before it is sent to the EFD\n",
    "- **time**: UTC timestamp in millisecons when the message is written to InfluxDB.\n",
    "\n",
    "Note that on March 3, the index timestamp changed to be the `private_sndStamp`.\n",
    "This was done to make the telemetry easier to analyze as the message index time would be when the telemetry was produced, not when it was ingested some time later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = Time('2020-02-27T12:00:00', scale='tai')\n",
    "window = TimeDelta(3600, format='sec', scale='tai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = await client.select_time_series(\"lsst.sal.MTM1M3.forceActuatorData\", [\"private_sndStamp\", \"private_kafkaStamp\"], t1-window, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency and time in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = numpy.array([(el - numpy.datetime64('1970-01-01T00:00:00')) / numpy.timedelta64(1, 's') for el in df.index.values])\n",
    "# Latency between SAL Kafka Producer and SAL\n",
    "df['latency1'] = (df['private_kafkaStamp'] - df['private_sndStamp'])\n",
    "\n",
    "# Latency between InfluxDB and SAL Kafka Producer, take into account the difference between UTC and TAI\n",
    "df['latency2'] = df['time'] - df['private_kafkaStamp'] + 37\n",
    "\n",
    "# Total latency, take into account the differece between UTC and TAI\n",
    "df['latency_total'] = df['time'] - df['private_sndStamp'] + 37\n",
    "\n",
    "\n",
    "df['time_seconds'] = df['time']-df['time'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency  characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df.latency1.median()\n",
    "quantile99 = df.latency1.quantile(.99)\n",
    "\n",
    "p = df.plot(x='time_seconds', y='latency1', figsize=(15,4))\n",
    "p.set_xlabel(\"Time (s)\")\n",
    "p.set_ylabel(\"Latency (s)\")\n",
    "_ = p.text(50,df.latency1.max()-0.01,\"Median={:.4f}s 99% percentile={:.2f}s\".format(median, quantile99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df.latency2.median()\n",
    "quantile99 = df.latency2.quantile(.99)\n",
    "\n",
    "p = df.plot(x='time_seconds', y='latency2', figsize=(15,4))\n",
    "p.set_xlabel(\"Time (s)\")\n",
    "p.set_ylabel(\"Latency (s)\")\n",
    "_ = p.text(50,df.latency2.max()-0.75,\"Median={:.4f}s 99% percentile={:.2f}s\".format(median, quantile99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df.latency_total.median()\n",
    "quantile99 = df.latency_total.quantile(.99)\n",
    "\n",
    "p = df.plot(x='time_seconds', y='latency_total', figsize=(15,4))\n",
    "p.set_xlabel(\"Time (s)\")\n",
    "p.set_ylabel(\"Latency (s)\")\n",
    "_ = p.text(50,df.latency_total.max()-0.75,\"Median={:.4f}s 99% percentile={:.2f}s\".format(median, quantile99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
