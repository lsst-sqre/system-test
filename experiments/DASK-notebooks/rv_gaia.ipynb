{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A demonstration of using Dask to visualize radial velocity data from the Gaia DR2 release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import holoviews.operation.datashader as hd\n",
    "import datashader as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask provides utilities to build clusters to use in distributed compute jobs.  In this particular case we will use a `LocalCluster`.  This is a cluster running within our container and sharing resources with other processes in this container: e.g. the notebook itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working in a dynamic environment where we don't know up front what ports/nodes our process will spawn on, there are a couple of utility classes that wrap dask classes to provide useful information about the running dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterlabutils.notebook import LSSTDaskClient, ClusterProxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example assumes you've asked for a `large` instance to work in.  That is 4CPUs and 12GB RAM.  Since we have 4 CPUs to work with, we will ask for 4 workers in our cluster with each having a single thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=4, threads_per_worker=1)\n",
    "client = LSSTDaskClient(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link above will take you to the status dashboard for the summary information about the cluster.\n",
    "\n",
    "The proxy in the next cell will give access to the status dashboards for each of the workers in your cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = ClusterProxy(client)\n",
    "proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the metadata for the parquet files we'll use for the analysis below.  This does not read all the data, but only the metadata for the 100 files in this data set.\n",
    "\n",
    "> Note that either of the methods in the cell will work when runing at the LDF, however direct posix filesystem access may not work if running in a different environment (e.g. GKE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet('/project/shared/data/gaia_dr2/gaia_source_with_rv.parquet/*', columns=['l', 'b', 'radial_velocity'], engine='fastparquet')\n",
    "#if reading from the cloud storage bucket, use the following instead\n",
    "#df = dd.read_parquet('gcs://jupyterlabdemo-gaia-dr2/gaia_source_with_rv.parquet/*', columns=['l', 'b', 'radial_velocity'], engine='fastparquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are stored with galactic longitude running from 0-360 degrees.  This puts the galactic center on the edge of the plot, so define a rotation to the longitude to make the galactic longitude running from -180-180."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_l(x):\n",
    "    l = x['l']\n",
    "    if l > 180.:\n",
    "        x['l'] = l-360.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the above function row by row.  This is a lazy operation and will not be performed until we ask for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(rot_l, axis=1, meta=(('l', 'float64'), ('b', 'float64'), ('radial_velocity','float64')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `compute` method applies all of the computatioins we've asked for and returns a `DataFrame` in memory.  Specifically, just return the `l`, `b`, and `radial_velocity` columns and perform the rotation on the galactic longitude in a row by row fashion.  To watch the progress, follow the link printed in the output of cell 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do things like count the number of rows.  This is no longer parallel, but is still fast because the data are in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to produce a map of the `radial_velocity` column aggregated over cells in on the sky.  Setting up the color map, we will set the most negative values to blue and the most positive values to red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.shade.cmap=[\"darkblue\", \"red\"]\n",
    "hv.extension(\"bokeh\", \"matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the points to be aggregated, `kdims` will be the spacial coordinates and `vdims` correspond to the color map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = hv.Points(df, kdims=['l', 'b'], vdims=['radial_velocity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the aggregation and display.  We specifiy the mean of the `radial_velocity` values in a cell as the value to place in a cell in the aggregated view.  Since we are using bokeh as the rendering library, the standard pan and zoom widgets are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%opts RGB [width=1000, height=500]\n",
    "hd.datashade(points, aggregator=ds.mean('radial_velocity'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see portions of the sky where the average star is coming toward us (blue) and portions where it is receeding (red).  Because the disk of the galaxy has differential rotaion, material outside the location of the Sun in the disk is revolving more slowly and material interior to the Sun, more quickly.  This manifests as the two embeded dipoles in the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close down the cluster\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
