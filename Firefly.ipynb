{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firefly Visualization Demo\n",
    "\n",
    "This notebook is intended to demonstrate the [Firefly](https://mospace.umsystem.edu/xmlui/handle/10355/5346) interactive interface for viewing image data. It also builds on the pedagogical explanations provided in [Getting started tutorial part 3](https://pipelines.lsst.io/getting-started/display.html) of the LSST Stack v15.0 documentation.\n",
    "\n",
    "This tutorial seeks to teach you about how to use the LSST Science Pipelines to inspect outputs from `processCcd.py` by displaying images and source catalogs in the Firefly image viewer. In doing so, you’ll be introduced to some of the LSST Science Pipelines’ Python APIs, including:\n",
    "\n",
    "* Accessing datasets with the `Butler`.\n",
    "* Displaying images with `lsst.afw.display`\n",
    "* Pass source catalog data directly to the `FireflyClient`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "This tutorial is meant to be run from the `jupyterhub` interface where the LSST stack is preinstalled. It assumes that the notebook is running a kernel with the `lsst_distrib` package set up.\n",
    "\n",
    "We start by importing packages from the LSST stack, Firefly, and standard python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSST stack imports\n",
    "from lsst.daf.persistence import Butler\n",
    "import lsst.afw.display as afw_display\n",
    "\n",
    "# Firefly client imports\n",
    "from firefly_client import FireflyClient\n",
    "\n",
    "# Standard libraries in support of Firefly display\n",
    "from urllib.parse import urlparse, urlunparse, ParseResult\n",
    "from IPython.display import display, Markdown, IFrame\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Butler client\n",
    "\n",
    "All data in the LSST Pipelines flow through the `Butler`. LSST does not recommend directly accessing processed image files. Instead, use the `Butler` client available from the `lsst.daf.persistence` module imported above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/project/shared/data/Twinkles_subset/output_data_v2'\n",
    "butler = Butler(datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Butler` client reads from the data repository specified with the inputs argument. In this specific case, the data were downloaded from: [here](https://lsst-web.ncsa.illinois.edu/~krughoff/data/twinkles_subset.tar.gz).  See the `README.txt` in `/project/shared/data/Twinkles_subset` for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing available data IDs in the Butler\n",
    "\n",
    "To get data from the `Butler` you need to know two things: the dataset type and the data ID.\n",
    "\n",
    "Every dataset stored by the Butler has a well-defined type. Tasks read specific dataset types and output other specific dataset types. The `processCcd.py` command reads in raw datasets and outputs calexp, or calibrated exposure, datasets (among others). It’s calexp datasets that you’ll display in this tutorial.\n",
    "\n",
    "Data IDs let you reference specific instances of a dataset. On the command line you select data IDs with `--id` arguments, filtering by keys like `visit`, `raft`, `ccd`, and `filter`.\n",
    "\n",
    "Now, use the `Butler` client to find what data IDs are available for the `calexp` dataset type:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butler.queryMetadata('calexp', ['visit', 'raft', 'sensor'], dataId={'filter': 'r'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printed output is a list of `(visit, raft, ccd)` key tuples for all data IDs where the filter key is the LSST r band. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get an exposure through the Butler\n",
    "\n",
    "Knowing a specific data ID, let’s get the dataset with the `Butler` client’s get method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataId = {'filter': 'r', 'raft': '2,2', 'sensor': '1,1', 'visit': 235}\n",
    "calexp = butler.get('calexp', **dataId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `calexp` is an `ExposureF` Python object. Exposures are powerful representations of image data because they contain not only the image data, but also a variance image for uncertainty propagation, a bit mask image plane, and key-value metadata. They can also contain WCS and PSF model information. In the next steps you’ll learn how to display an Exposure’s image and mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Display\n",
    "\n",
    "To display the `calexp` you will use the LSST `afwDisplay` framework, which is imported as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.afw.display as afwDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The display framework provides a uniform API for multiple display backends, including DS9, matplotlib, and LSST’s Firefly viewer. The default backend is `ds9`, but since we are working remotely on `jupyterhub` we would prefer to use the web-based Firefly display."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we do some setup for the Firefly backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_channel = '{}_test_channel'.format(os.environ['USER'])\n",
    "server = 'https://lsst-lspdev.ncsa.illinois.edu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a Firefly IFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff='{}/firefly/slate.html?__wsch={}'.format(server, my_channel)\n",
    "IFrame(ff,800,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afwDisplay.setDefaultBackend('firefly')\n",
    "afw_display = afwDisplay.getDisplay(frame=1, \n",
    "                                    host=server,\n",
    "                                    name=my_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the calexp (calibrated exposure)\n",
    "\n",
    "We can now build the display and use the `mtv` method to view the `calexp` with Firefly. First we display an image with mask planes and then overplot some sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afw_display.mtv(calexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As soon as you execute the command a single simulated, calibrated LSST exposure, the `{'filter': 'r', 'raft': '2,2', 'sensor': '1,1', 'visit': 235}` data ID, should appear in the Firefly browser window.\n",
    "\n",
    "Notice that the image is overlaid with colorful regions. These are mask regions. Each color reflects a different mask bit that correspond to detections and different types of detector artifacts. You’ll learn how to interpret these colors later, but first you’ll likely want to adjust the image display."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the image display\n",
    "\n",
    "The display framework gives you control over the image display to help bring out image details. For example, to make masked regions semi-transparent, so that underlying image features are visible, try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afw_display.setMaskTransparency(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setMaskTransparency method’s argument can range from 0 (fully opaque) to 100 (fully transparent).\n",
    "\n",
    "You can also control the colorbar scaling algorithm with the display’s scale method. Try an asinh stretch with explicit minimum (black) and maximum (white) values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afw_display.scale(\"asinh\", -1, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use an automatic algorithm like `zscale` (or `minmax`) to select the white and black thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afw_display.scale(\"asinh\", \"zscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting displayed mask colors\n",
    "\n",
    "The display framework renders each plane of the mask in a different color (plane being a different bit in the mask). To interpret these colors you can get a dictionary of mask planes from the `calexp` and query the display for the colors it rendered each mask plane with. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = calexp.getMask()\n",
    "for maskName, maskBit in mask.getMaskPlaneDict().items():\n",
    "    print('{}: {}'.format(maskName, afw_display.getMaskPlaneColor(maskName)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting sources on the display\n",
    "\n",
    "The LSST processing pipeline also creates a table of the sources it used for PSF estimation as well as astrometric and photometric calibration. The dataset type of this table is `src`, which you can get from the Butler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = butler.get('src', **dataId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned object, `src`, is a `lsst.afw.table.SourceTable` object. `SourceTables` are explored more elsewhere, but you can do some simple investigations using common python functions. For example, to check the length of the object:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view an HTML rendering of the `src` table by getting an `astropy.table.Table` version of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.asAstropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll overplot sources from the `src` table onto the image display using the Display’s `dot` method for plotting markers. `Display.dot` plots markers individually, so you’ll need to iterate over rows in the `SourceTable`. Next we display the first 100 sources. We limit the number of sources since plotting the whole catalog is a serial process and takes some time. Because of this, it is more efficient to send a batch of updates to the display, so we enclose the loop in a `display.Buffering` context, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with afw_display.Buffering():\n",
    "    for record in src[:100]:\n",
    "        afw_display.dot('o', record.getX(), record.getY(), size=20, ctype='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first 100 sources are preferentially located at the bottom of the image. This spatial ordering is likely imprinted by the source detection algorithm; however, it could change due to parallelization. The units o the `size` parameter are believed to be pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearing markers\n",
    "\n",
    "`Display.dot` always adds new markers to the display. To clear the display of all markers, use the erase method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afw_display.erase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using FireflyClient directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the Firefly client directly to make plots and add catalogs to the visualization.  First construct the `FireflyClient` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = server\n",
    "html = \"slate.html\"\n",
    "fc = FireflyClient(host, channel=my_channel, html_file=html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a FITS file to pass to Firefly. This gives us the opportunity to play with the `src` table a bit. Let's select just the sources that were used to fit the PSF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_src = src[src['calib_psfUsed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we persist the catalog to local storage and then upload it to Firefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_src.writeFits('psf_src.fits')\n",
    "src_key = fc.upload_file('psf_src.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the file is uploaded, we can have Firefly generate and display a scrollable table view widget.  Note that the label you give the table here, `tbl_id='src'`, is how you will refer to that dataset in future plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = fc.show_table(src_key, tbl_id='src', page_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we specify several style options for the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout1 = dict(\n",
    "               title='test ap flux/model mag vs. log(ap flux)', \n",
    "               xaxis=dict(title='Model'), \n",
    "               yaxis=dict(title='Ap/Model')\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify the data to plot. Note the reference to `'src'`.  That allows for columnar math in the construction of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = dict(\n",
    "              tbl_id='src', \n",
    "              x='tables::base_CircularApertureFlux_12_0_flux/base_GaussianFlux_flux',\n",
    "              y='tables::log10(base_CircularApertureFlux_12_0_flux)',\n",
    "              mode='markers',\n",
    "              type='scatter',\n",
    "              marker=dict(size=4)\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can send the plot to the visualization canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = fc.show_chart(layout=layout1, data=[trace1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots are rendered by `plotly`, so follow the same syntax for construction.  For info on `plotly` see the [primer](https://plot.ly/python/getting-started/) and [examples](https://plot.ly/python/line-and-scatter/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap up\n",
    "In this tutorial we have used the `Butler` to access LSST simulation data and used the LSST Science Pipelines Python API to display images and tables. Here are some key takeaways:\n",
    "\n",
    "* Use the `lsst.daf.persistence.Butler` class to read and write data from repositories.\n",
    "* The `lsst.afw.display` module provides a flexible framework for sending data from LSST Science Pipelines code to image displays. We used the Firefly backend for web-based visualization (`ds9`, `matplotlib`, and `ginga` are other avialable backends).\n",
    "* `Exposure` objects have image data, mask data, and metadata. When you display an Exposure, the display framework automatically overlays mask planes.\n",
    "* We have accessed and visualized the Table of sources extracted from an image. The `Table.asAstropy` method can be used to view the table as an `astropy.table.Table`.\n",
    "* We have sent a subset of objects to directly to the Firefly API for additional plotting and investigation.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST_Stack (Python 3)",
   "language": "python",
   "name": "lsst_stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
